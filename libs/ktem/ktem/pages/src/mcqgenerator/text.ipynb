{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T04:21:21.792321500Z",
     "start_time": "2024-09-24T04:21:21.780344500Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "quiz_str=\"\"\"{\n",
    "\"1\": {\n",
    "\"mcq\": \"在深度学习的发展历史中，哪一阶段被认为是神经网络发展的第一个高潮期？\",\n",
    "\"options\": {\n",
    "\"a\": \"第一阶段：模型提出\",\n",
    "\"b\": \"第二阶段：冰河期\",\n",
    "\"c\": \"第三阶段：反向传播算法引起的复兴\",\n",
    "\"d\": \"以上都不对\"\n",
    "},\n",
    "\"correct\": \"a\"\n",
    "},\n",
    "\"2\": {\n",
    "\"mcq\": \"哪一位科学家提出了Perceptron（感知器）的概念？\",\n",
    "\"options\": {\n",
    "\"a\": \"Warren McCulloch\",\n",
    "\"b\": \"Walter Pitts\",\n",
    "\"c\": \"Marvin Minsky\",\n",
    "\"d\": \"Alan Turing\"\n",
    "},\n",
    "\"correct\": \"c\"\n",
    "},\n",
    "\"3\": {\n",
    "\"mcq\": \"哪种方法被用于训练Neocognitron（新知机）？\",\n",
    "\"options\": {\n",
    "\"a\": \"监督学习\",\n",
    "\"b\": \"无监督学习\",\n",
    "\"c\": \"概率密度估计\",\n",
    "\"d\": \"自动微分\"\n",
    "},\n",
    "\"correct\": \"b\"\n",
    "}\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "quiz_dict=json.loads(quiz_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2b458a6050196c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T01:58:25.300297700Z",
     "start_time": "2024-09-08T01:58:25.295746300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "列表wei空\n"
     ]
    }
   ],
   "source": [
    "if not quiz_str_list:\n",
    "    print(\"列表wei空\")\n",
    "else:\n",
    "    print(\"列表fei空\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b95a757a74b88c36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T01:46:06.050827200Z",
     "start_time": "2024-09-08T01:46:06.044450100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if quiz_str_list:\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4bcaf4d74c2a22f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T07:13:48.692482800Z",
     "start_time": "2024-09-14T07:13:48.649984600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"1\": {\\n        \"mcq\": \"multiple choice question\",\\n        \"options\": {\\n            \"a\": \"choice here\",\\n            \"b\": \"choice here\",\\n            \"c\": \"choice here\",\\n            \"d\": \"choice here\"\\n        },\\n        \"correct\": \"correct answer\"\\n    },\\n    \"2\": {\\n        \"mcq\": \"multiple choice question\",\\n        \"options\": {\\n            \"a\": \"choice here\",\\n            \"b\": \"choice here\",\\n            \"c\": \"choice here\",\\n            \"d\": \"choice here\"\\n        },\\n        \"correct\": \"correct answer\"\\n    },\\n    \"3\": {\\n        \"mcq\": \"multiple choice question\",\\n        \"options\": {\\n            \"a\": \"choice here\",\\n            \"b\": \"choice here\",\\n            \"c\": \"choice here\",\\n            \"d\": \"choice here\"\\n        },\\n        \"correct\": \"correct answer\"\\n    }\\n}'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('/data_G/zhenyang/Project_all/mcqgen/Response.json','r') as R_file, open('/data_G/zhenyang/Project_all/mcqgen/examples.json','r') as E_file:\n",
    "    # RESPONSE_JSON = json.load(R_file)\n",
    "    # EXAMPLES_JSON = json.load(E_file)\n",
    "    content1 = R_file.read()\n",
    "    content2 = E_file.read()\n",
    "\n",
    "content1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3dbe01b2f7cf1467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T08:08:56.160641900Z",
     "start_time": "2024-09-14T08:08:56.160047900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-14 16:08:56.152 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import json\n",
    "\n",
    "# 示例多项选择题数据\n",
    "quiz_data = {\n",
    "    \"questions\": [\n",
    "        {\n",
    "            \"question\": \"图灵奖在计算机科学领域的地位如何？它与Marvin Minsky有什么关系？\",\n",
    "            \"options\": {\n",
    "                \"A\": \"图灵奖是计算机科学领域的国际最高奖项，Marvin Minsky因其在人工智能领域的贡献于1969年获此奖\",\n",
    "                \"B\": \"图灵奖是计算机科学领域的国际最高奖项，Marvin Minsky因其在专家系统领域的贡献于1969年获此奖\",\n",
    "                \"C\": \"图灵奖是计算机科学领域的国际二级奖项，Marvin Minsky因其在神经网络领域的贡献于1969年获此奖\",\n",
    "                \"D\": \"图灵奖是计算机科学领域的国家级奖项，Marvin Minsky因其在机器学习领域的贡献于1969年获此奖\"\n",
    "            },\n",
    "            \"correct\": \"A\",\n",
    "            \"explanation\": \"图灵奖是计算机科学的最高奖项，Marvin Minsky因其在人工智能的贡献获奖。\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"关于人工智能的发展历程，以下哪项描述是正确的？\",\n",
    "            \"options\": {\n",
    "                \"A\": \"深度学习是人工智能发展的最终阶段，已经解决了所有人工智能问题\",\n",
    "                \"B\": \"人工智能的发展始于1940年代，但直到1980年代才真正成为热门学科\",\n",
    "                \"C\": \"人工智能经历了推理期、知识明确学习期三个主要阶段，各阶段之间没有重叠\",\n",
    "                \"D\": \"专家系统在人工智能的知识明确学习期广泛应用，但很快被机器学习方法完全取代\"\n",
    "            },\n",
    "            \"correct\": \"B\",\n",
    "            \"explanation\": \"人工智能在1940年代开始发展，1980年代深度学习开始成为研究热点。\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "def quiz_app(quiz_data):\n",
    "    # 标题\n",
    "    st.title(\"人工智能与神经网络的发展历程\")\n",
    "    \n",
    "    # 显示问题\n",
    "    for idx, question_data in enumerate(quiz_data[\"questions\"], start=1):\n",
    "        st.subheader(f\"问题 {idx}: {question_data['question']}\")\n",
    "        \n",
    "        # 显示选项\n",
    "        user_answer = st.radio(\n",
    "            f\"请选择一个答案：\",\n",
    "            options=list(question_data[\"options\"].keys()),\n",
    "            key=f\"q{idx}\"\n",
    "        )\n",
    "        \n",
    "        # 显示用户选择的答案\n",
    "        st.write(f\"你选择了: {question_data['options'][user_answer]}\")\n",
    "        \n",
    "        # 是否显示答案解析\n",
    "        if st.checkbox(f\"显示问题 {idx} 的答案解析\"):\n",
    "            st.write(f\"正确答案: {question_data['correct']}\")\n",
    "            st.write(f\"解析: {question_data['explanation']}\")\n",
    "    \n",
    "    # 编辑模式（允许编辑问题和选项）\n",
    "    if st.checkbox(\"进入编辑模式\"):\n",
    "        for idx, question_data in enumerate(quiz_data[\"questions\"], start=1):\n",
    "            st.text_area(f\"编辑问题 {idx}:\", value=question_data['question'], key=f\"edit_q{idx}\")\n",
    "            for opt_key in question_data[\"options\"]:\n",
    "                st.text_input(f\"选项 {opt_key}:\", value=question_data[\"options\"][opt_key], key=f\"edit_q{idx}_{opt_key}\")\n",
    "\n",
    "    # 导出按钮（保存用户的回答）\n",
    "    if st.button(\"保存结果\"):\n",
    "        with open(\"quiz_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(quiz_data, f, ensure_ascii=False, indent=4)\n",
    "        st.success(\"结果已保存\")\n",
    "\n",
    "    # 导出下载按钮\n",
    "    st.download_button(\n",
    "        label=\"导出结果\",\n",
    "        data=json.dumps(quiz_data, ensure_ascii=False),\n",
    "        file_name=\"quiz_results.json\",\n",
    "        mime=\"application/json\"\n",
    "    )\n",
    "\n",
    "# 调用测试函数\n",
    "quiz_app(quiz_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165fd727ab1a0b77",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from llm import get_llm\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "sys_prompt=template=\"\"\"\n",
    "# Role: 单项选择题的编写专家，多年执教经验的老师、命题人，懂得易错点和重点知识\n",
    "\n",
    "## Background: \n",
    "- 我希望能够根据一段知识点文本和要求生成一套高质量的单项选择题，能够通过试题反应出学生的知识掌握水平。\n",
    "\n",
    "## Attention:\n",
    "- 优秀的单项选择题是我们评估学生对知识掌握程度的重要工具。如果题目设计不当，无法准确反映学生的实际水平，可能会导致筛选出的学生并不真正掌握学科知识。因此，请务必高度重视题目设计的质量，确保能够筛选出对学科知识掌握牢固且正确的优秀学生。\n",
    "\n",
    "## Goals:\n",
    "- 题型要多样化、命题思路要严谨、涉及的知识点要全面的单项选择题，能够准确反馈出学生对知识的真实掌握程度。\n",
    "- 试题需要主题明确、知识点针对性强，错误选项需具有一定的干扰性，即看似合理但实则错误。正确答案决不允许胡编乱造。\n",
    "- 给定文本，你的任务是制作一个包含5道单项选择题的深度学习学科测验\n",
    "- 问题难度为：困难。\n",
    "\n",
    "## Workflows:\n",
    "1. 第一步：明确题目主题:\n",
    "2. 第二步：列出至少3个与主题紧密相关的关键知识点:\n",
    "3. 第三步：基于知识点文本，确保制作5道单项选择题，每道题须有4个选项，有且只有一个正确选项，，确保按照RESPONSE_JSON的格式组织你的回答，并将其作为指南。RESPONSE_JSON={response_json}\n",
    "\n",
    "## Rules:\n",
    "- 第三步必须是json格式(例如：```json内容..```)，确保按照RESPONSE_JSON的格式组织你的回答\n",
    "- 精心设计易错点，干扰选项需要有意义，使得干扰选项能够考验学生对知识点的掌握\n",
    "- 相关性——主题的具体性和复杂性 \n",
    "- 准确性——题干和正确答案必须有所依据 \n",
    "- 合理性——答案是一定存在的、高质量的、在上下文中有意义的\n",
    "- 清晰度——易于阅读；不混淆\n",
    "- 对于不精准或模棱两可的知识，请不要加入到试题中以免引起歧义。\n",
    "- 作为角色 <Role>, 严格遵守<Workflows>, 默认以中文语言完成要求。 \n",
    "\n",
    "## Examples:\n",
    "- {examples}\n",
    "\n",
    "\n",
    "## Text:\n",
    "你需要根据知识点文本来设计多选题，以下是知识点文本：\n",
    "{text}\n",
    "\"\"\"\n",
    "llm,_ = get_llm(\"Ollama\")\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",sys_prompt),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "response_json=\"\"\"{\"1\": {\"question\": \"choice here\", \"C\": \"choice here\", \"D\": \"choice here\"}, \"correct\": \"correct answer\", \"explanation\": \"Detailed option explanations\"}, \"2\": {\"question\": \"multiple choice question\", \"options\": {\"A\": \"choice here\", \"B\": \"choice here\", \"C\": \"choice here\", \"D\": \"choice here\"}, \"correct\": \"correct answer\", \"explanation\": \"Detailed option explanations\"}, \"3\": {\"question\": \"multiple choice question\", \"options\": {\"A\": \"choice here\", \"B\": \"choice here\", \"C\": \"choice here\", \"D\": \"choice here\"}, \"correct\": \"correct answer\", \"explanation\": \"Detailed option explanations\"}}\"\"\"\n",
    "text=\"\"\"[Document(page_content='Entities:\\n- {\\'descriptionText\\': \\'图灵机是艾伦·图灵提出的一种抽象计算模型，它在可计算性问题以及人工智能发展史上具有非常重要的意义，并对计算机科学产生了深远Hebbian法则是一种关于神经网络学习的理论\\', \\'entityName\\': \\'HEBBIAN法则\\'}\\n- {\\'descriptionText\\': \\'图灵奖是计算机科学领域的国际最高奖项，Marvin Minsky于1969年获得此奖项\\', \\'enti\\'福岛邦彦提出了新知机模型\\', \\'entityName\\': \\'福岛邦彦\\'}\\n- {\\'descriptionText\\': \\'B型图灵机是一种可以基于Hebbian法则进行学习的机器\\', \\'entityName\\': \\'B型图灵机\\'}\\n- {\\'descri带卷积和子采样操作的多层神经网络由福岛邦彦提出的多层神经网络结构，采用无监督学习方式训练\\', \\'entityName\\': \\'新知机\\'}\\n- {\\'descriptionText\\': \\'赫布理论是Donald Hebb提出的关于神经: \\'Torch3是Lua语言的一个深度学习库，是PyTorch的前身\\', \\'entityName\\': \\'TORCH3\\'}\\n- {\\'descriptionText\\': \\'图灵测试是图灵提出的一个测试计算机能否展现出智能行为的准则\\', \\'entityN\\': \\'赫布型学习是基于赫布理论的学习方法\\', \\'entityName\\': \\'赫布型学习\\'}\\nReports:\\n- {\\'rank\\': 6.5, \\'weight\\': None, \\'summaryText\\': \"The community is centered around the concal Networks (ANN), which is a machine learning structure simulating the human brain\\'s neural network. Key entities include neurons, perceptrons, nodes, and various related concepts and individuals such as Donald Hebb and Rosenblatt. These entities are interconnected through relationships that define their roles and contributions to the field of artificial intelligence and machine learning.\"}\\n- {\\'rank\\': 6.5, \\'weight\\': None, \\'summaryText\\': \"The community is centered around the works of Donald Hebb, a renowned Canadian neuro-psychologist, and his contributions to the field of psychology, particularly his theories on learning and synaptic plasticity. The entities in this community are primarily theoretical concepts and professional entities directly linked to Hebb\\'s work and legacy.\"}\\n- {\\'rank\\': 6.5, \\'weight\\': None, \\'summaryText\\': \"The community is centered around the concept of Artificial Neural Networks (ANN), which is a machine learning structure simulating the human brain\\'s neural network. Key entities include neurons, perceptrons, nodes, and various related concepts and individuals such as Donald Hebb and Rosenblatt. These entities are interconnected through relationships that define their roles and contributions to the field of artificial intelligence and machine learning.\"}\\nChunks:\\n- {\\'chunkText\\': \\'函数），因此我们可以将人工神经网络看作一个可学习的函数，并将其应用到机器学习中．理论上，只要有足够的训练数据和神（Network Capacity），这与可以被储存在网络中的信息的复杂度以及数量相关．\\\\n1.5.3神经网络的发展历史神经网络的发展大致经过五个阶段．\\\\n第一阶段：模型提出第一阶段为1943 年～1969 年，是神和数学家Walter Pitts 最早提出了一种基于简单逻辑运算的人工神经网络，这种神经网络模型称为MP 模型，至此开启了人工神经网络研究的序幕．1948 年，Alan Turing 提出了一种“B 型图灵机”．\\\\n“B 型tts 的学生Marvin Minsky 建造了第一台神经网络机SNARC．\\\\nMarvin Minsky（1927～2016），人工智能领域最重要的领导者和创新者之一，麻省理工学院人工智能实验室的创始人之一．\\\\n因其在人工智能拟人类感知能力的神经网络模型，称为感知器（Percep-tron），并提出了一种接近于人类学习过程（迭代、试错）的学习算法．\\\\n在这一时期，神经网络以其独特的结构和处理信息的方法，在许多实际应用处于长年停滞及低潮状态．\\\\n1969 年，Marvin Minsky 出版《感知器》一书，指出了神经网络的两个关键缺陷：一是感知器无法处理“异或”回路问题；二是当时的计算机无法支持处理大https://nndl.githu的神经网络产生质疑，并导致神经网络的研究进入了十多年的“冰河期”．\\\\n但在这一时期，依然有不少学者提出了很多有用的模型或算法．1974 年，哈佛大学的Paul Werbos 发明反向传播算法（BackPropagNeocognitron）[Fukushima, 1980]．\\\\n新知机的提出是受到了动物初级视皮层简单细胞和复杂细胞的感受野的启发．\\\\n但新知机并没有采用反向传播算法，而是采用了无监督学习的方式来训练，因此也没有播算法重新�\\', \\'chunkId\\': \\'0a5689249dea5fa6e3eb9ba870a10ba4\\', \\'frequency\\': 5}\\n- {\\'chunkText\\': \\'科．\\\\n图1.1给出了人工智能发展史上的重要事件．\\\\n1940194519501955196019651970005McCulloch 和Pitts提出人工神经元网络图灵机达特茅斯会议Rosenblatt提出“感知器”推理期知识期学习期知识系统兴起专家系统兴起神经网络重新流行统计机器学习兴起（支持向量机等）深度学习的兴起然遥遥无期．\\\\nhttps://nndl.github.io/page_begin1.2机器学习2021 年5 月18 日61.1.2人工智能的流派目前我们对人类智能的机理依然知之甚少，还没有一个通用的理论来指导如何构建一个人工智能系统究人类智能的机理来构建一个仿生的模拟系统，而另外一些研究者则认为可以使用其他方法来实现人类的某种智能行为．\\\\n一个著名的例子是让机器具有飞行能力不需要模拟鸟的飞行方式，而是应该研究空气接主义和行为主义三种，其中行为主义（Actionism）主要从生物进化的角度考虑，主张从和外界环境的互动中获取智能．\\\\n（1）符号主义（Symbolism），又称逻辑主义、心理学派或计算机学派，是指通过作．\\\\n人类的认知过程可以看作符号操作过程．\\\\n在人工智能的推理期和知识期，符号主义的方法比较盛行，并取得了大量的成果．\\\\n（2）连接主义（Connectionism），又称仿生学派或生理学派，是认知经网络中的信息处理过程，而不是符号运算．\\\\n因此，连接主义模型的主要结构是由大量简单的信息处理单元组成的互联网络，具有非线性、分布式、并行化、局部性计算以及自适应性等特性．\\\\n符号主义主要模型神经网络就是一种连接主义模型．\\\\n随着深度学习的发展，越来越多的研究者开始关注如何融合符号主义和连接主义，建立一种高效并且具有可解释性的模型．\\\\n1.2机器学习机器学习（Machine LnkId\\': \\'8baca4b3f4003191a17a1f82b043fa52\\', \\'frequency\\': 2}\\n- {\\'chunkText\\': \\'学家Donald Hebb 在《行为的组织》（The Organization of Behavior）一书中提出突触可塑性的基本原理，D理学家，认知心理生理学的开创者．\\\\n“当神经元A 的一个轴突和神经元B 很近，足以对它产生影响，并且持续地、重复地参与了对神经元B 的兴奋，那么在这两个神经元或其中之一会发生某种生长过程或新或Hebb’s Rule）．\\\\n如果两个神经元总是相关联地受到刺激，它们之间的突触强度增加．\\\\n这样的学习方法被称为赫布型学习（Hebbian learning）．\\\\nHebb 认为人脑有两种记忆：长期记忆和短期记忆．固作用．\\\\n人脑中的海马区为大脑结构凝固作用的核心区域．\\\\n1.5.2人工神经网络人工神经网络是为模拟人脑神经网络而设计的一种计算模型，它从结构、实现机理和功能上模拟人脑神经网络．\\\\n人工神另一个节点的影响大小．\\\\n每个节点代表一种特定函数，来自其他节点的信息经过其相应的1 图片来源：https://commons.wikimedia.org/wiki/File:Neuron_Hand-tuned.svghttps://nndl.github.io/page_begin1.5神经网络2021 年5 月18 日14权重综合计算，输入到一个激活函数中并得到一个新的活性值（兴奋或抑制）．\\\\n从系统观点看，人工神经元网络是由大量神经元通过极其丰富和完善的连接而构成的自学习能力．\\\\n首个可学习的人工神经网络是赫布网络，采用一种基于赫布规则的无监督学习方法．\\\\n感知器是最早的具有机器学习思想的神经网络，但其学习方法无法扩展到多层的神经网络上．\\\\n感知器参习问题．\\\\n在本书中，人工神经网络主要是作为一种映射函数，即机器学习中的模型．\\\\n由于人工神经网络可以用作一个通用的函数逼近器（一个两层的神经网络可以逼近任意的函数），因此我们可以将人函数的能力\\', \\'chunkId\\': \\'84a8a6e9ba478ecb40b16e75fb368359\\', \\'frequency\\': 2}\\nRelationships:\\n- {\\'entityFrom\\': \\'图灵奖\\', \\'entityTo\\': \\'MARVIN MINSKY\\', \\'descriptionText\\vin Minsky因其在人工智能领域的贡献而获得图灵奖\\', \\'relation\\': \\'RELATED\\'}\\n- {\\'entityFrom\\': \\'赫布理论\\', \\'entityTo\\': \\'DONALD HEBB\\', \\'descriptionText\\': \\'Donald Hebb提出了ELATED\\'}\\n- {\\'entityFrom\\': \\'TORCH3\\', \\'entityTo\\': \\'PYTORCH\\', \\'descriptionText\\': \\'Torch3是PyTorch的前身，两者在技术继承上有关联\\', \\'relation\\': \\'RELATED\\'}\\n- {\\'entityFr \\'entityTo\\': \\'人工神经网络\\', \\'descriptionText\\': \\'赫布型学习是早期人工神经网络的一种学习方式赫布网络是首个可学习的人工神经网络，采用基于赫布规则的无监督学习方法\\', \\'relation\\'工智能\\', \\'descriptionText\\': \\'图灵机对人工智能的理论基础有重要贡献\\', \\'relation\\': \\'RELATED\\'}\\n- {\\'entityFrom\\': \\'福岛邦彦\\', \\'entityTo\\': \\'新知机\\', \\'descriptionText\\': \\网络的结构提供了新的视角\\', \\'relation\\': \\'RELATED\\'}\\n- {\\'entityFrom\\': \\'新知机\\', \\'entityTo\\': \\'福岛邦彦\\', \\'descriptionText\\': \\'福岛邦彦提出了新知机模型福岛邦彦提出新知机模TED\\'}\\n- {\\'entityFrom\\': \\'图灵机\\', \\'entityTo\\': \\'TURING TEST\\', \\'descriptionText\\': \\'图灵机模型和图灵测试都由图灵提出，对人工智能领域有深远影响\\', \\'relation\\': \\'RELATED\\'}\\T\\', \\'entityTo\\': \\'图灵机\\', \\'descriptionText\\': \\'图灵机模型和图灵测试都由图灵提出，对人工智能领域有深远影响\\', \\'relation\\': \\'RELATED\\'}\\n- {\\'entityFrom\\': \\'赫布理论\\', \\'entt\\': \\'赫布型学习是基于赫布理论的学习方法\\', \\'relation\\': \\'RELATED\\'}\\n- {\\'entityFrom\\'\"\"\"\n",
    "examples=\"\"\"{\n",
    "    \"1\": {\n",
    "        \"question\": \"关于强化学习和神经网络模型的结合使用，以下哪些描述是正确的？\",\n",
    "        \"options\": {\n",
    "            \"A\": \"强化学习可以看作是一种端到端的学习方法，其中每个内部组件直接从最终奖励中学习。\",\n",
    "            \"B\": \"在深度强化学习中，贡献度分配问题指的是如何合理地将整体奖励分配给各个决策步骤。\",\n",
    "            \"C\": \"误差反向传播算法主要用于监督学习，而不是强化学习。\",\n",
    "            \"D\": \"强化学习中的智能体通过与环境交互来优化策略，而不需要显式的训练数据集。\"\n",
    "        },\n",
    "        \"correct\": \"B, D\",\n",
    "        \"explanation\": \"B. 贡献度分配问题是深度强化学习中的一个关键问题，涉及如何将整体奖励分配给各个决策步骤。D. 强化学习的核心是通过与环境交互来学习最优策略，而不依赖于预先标记的数据集。A. 选项描述不准确，强化学习通常不是纯粹的端到端学习；C. 反向传播算法确实主要应用于监督学习，但在某些情况下也可用于强化学习中的策略梯度方法。\"\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"question\": \"下列关于神经元及其在人工神经网络中的模拟，哪几项是正确的？\",\n",
    "        \"options\": {\n",
    "            \"A\": \"神经元之间的连接强度（突触权重）在人工神经网络中是固定不变的。\",\n",
    "            \"B\": \"Hebbian理论认为，当两个神经元同时被激活时，它们之间的连接会变得更强。\",\n",
    "            \"C\": \"反向传播算法是由Paul Werbos提出的，它解决了多层神经网络中贡献度分配的问题。\",\n",
    "            \"D\": \"在生物神经元中，树突负责接收来自其他神经元的信息，轴突则负责传递信息至下一个神经元或效应器。\"\n",
    "        },\n",
    "        \"correct\": \"B, C, D\",\n",
    "        \"explanation\": \"B. Hebbian理论强调了神经元之间连接强度的可塑性，这是学习的基础。C. Paul Werbos确实在1974年提出了反向传播算法，该算法对于解决多层神经网络中的权重更新问题至关重要。D. 树突和轴突的功能正如所述。A. 神经网络中的突触权重是通过学习过程不断调整的，并非固定不变。\"\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"question\": \"关于特征表示方法以及其在机器学习中的应用，下列说法正确的是？\",\n",
    "        \"options\": {\n",
    "            \"A\": \"one-hot编码适合于表示连续变量。\",\n",
    "            \"B\": \"局部分表示如one-hot向量，通常用于表示离散特征，例如颜色。\",\n",
    "            \"C\": \"分布式表示相较于one-hot编码，能更好地捕捉特征间的相似性。\",\n",
    "            \"D\": \"嵌入（Embedding）技术仅适用于自然语言处理领域。\"\n",
    "        },\n",
    "        \"correct\": \"B, C\",\n",
    "        \"explanation\": \"B. one-hot向量常用来表示离散特征，比如不同的颜色。C. 分布式表示能够表达特征间的语义关系，这在one-hot编码中是无法实现的。A. one-hot编码不适合表示连续变量，因为它是为离散变量设计的。D. 嵌入技术不仅限于自然语言处理，也广泛应用于推荐系统等领域。\"\n",
    "    }\n",
    "}\"\"\"\n",
    "# Set up the language model and memory chain\n",
    "chain = prompt | llm\n",
    "user_input=\"请开始：\"\n",
    "chain.invoke({\"question\":user_input,\"examples\": examples,\"text\":text,\"response_json\":response_json})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "353ec285",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'code': '1214', 'message': 'messages 参数非法。请检查文档。'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 103\u001b[0m\n\u001b[1;32m    101\u001b[0m chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m llm\n\u001b[1;32m    102\u001b[0m user_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m请开始：\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 103\u001b[0m result\u001b[38;5;241m=\u001b[39m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexamples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m pprint(result)\n",
      "File \u001b[0;32m~/.conda/envs/kotaemon/lib/python3.10/site-packages/langchain_core/runnables/base.py:2879\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2877\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2878\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2879\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2880\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2881\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/kotaemon/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:277\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    274\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    276\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 277\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    287\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/.conda/envs/kotaemon/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:777\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    771\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    775\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    776\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 777\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/kotaemon/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:634\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    633\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 634\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    635\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    636\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    638\u001b[0m ]\n\u001b[1;32m    639\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/.conda/envs/kotaemon/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:624\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 624\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m         )\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.conda/envs/kotaemon/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:846\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 846\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/kotaemon/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:686\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[0;32m~/.conda/envs/kotaemon/lib/python3.10/site-packages/openai/_utils/_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/kotaemon/lib/python3.10/site-packages/openai/resources/chat/completions.py:704\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    701\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    702\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    703\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/kotaemon/lib/python3.10/site-packages/openai/_base_client.py:1270\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1258\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1265\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1267\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1268\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1269\u001b[0m     )\n\u001b[0;32m-> 1270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.conda/envs/kotaemon/lib/python3.10/site-packages/openai/_base_client.py:947\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    945\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/kotaemon/lib/python3.10/site-packages/openai/_base_client.py:1051\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1048\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1050\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1054\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1055\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1059\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1060\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'code': '1214', 'message': 'messages 参数非法。请检查文档。'}}"
     ]
    }
   ],
   "source": [
    "from llm import get_llm\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "sys_prompt=template=\"\"\"\n",
    "# Role: 单项选择题的编写专家，多年执教经验的老师、命题人，懂得易错点和重点知识\n",
    "\n",
    "## Background: \n",
    "- 我希望能够根据一段知识点文本和要求生成一套高质量的单项选择题，能够通过试题反应出学生的知识掌握水平。\n",
    "\n",
    "## Attention:\n",
    "- 优秀的单项选择题是我们评估学生对知识掌握程度的重要工具。如果题目设计不当，无法准确反映学生的实际水平，可能会导致筛选出的学生并不真正掌握学科知识。因此，请务必高度重视题目设计的质量，确保能够筛选出对学科知识掌握牢固且正确的优秀学生。\n",
    "\n",
    "## Goals:\n",
    "- 题型要多样化、命题思路要严谨、涉及的知识点要全面的单项选择题，能够准确反馈出学生对知识的真实掌握程度。\n",
    "- 试题需要主题明确、知识点针对性强，错误选项需具有一定的干扰性，即看似合理但实则错误。正确答案决不允许胡编乱造。\n",
    "- 给定文本，你的任务是制作一个包含5道单项选择题的深度学习学科测验\n",
    "- 问题难度为：困难。\n",
    "\n",
    "## Workflows:\n",
    "1. 第一步：明确题目主题:\n",
    "2. 第二步：列出至少3个与主题紧密相关的关键知识点:\n",
    "3. 第三步：基于知识点文本，确保制作5道单项选择题，每道题须有4个选项，有且只有一个正确选项，，确保按照RESPONSE_JSON的格式组织你的回答，并将其作为指南。RESPONSE_JSON={response_json}\n",
    "\n",
    "## Rules:\n",
    "- 第三步必须是json格式(例如：```json内容..```)，确保按照RESPONSE_JSON的格式组织你的回答\n",
    "- 精心设计易错点，干扰选项需要有意义，使得干扰选项能够考验学生对知识点的掌握\n",
    "- 相关性——主题的具体性和复杂性 \n",
    "- 准确性——题干和正确答案必须有所依据 \n",
    "- 合理性——答案是一定存在的、高质量的、在上下文中有意义的\n",
    "- 清晰度——易于阅读；不混淆\n",
    "- 对于不精准或模棱两可的知识，请不要加入到试题中以免引起歧义。\n",
    "- 作为角色 <Role>, 严格遵守<Workflows>, 默认以中文语言完成要求。 \n",
    "\n",
    "## Examples:\n",
    "- {examples}\n",
    "\n",
    "\n",
    "## Text:\n",
    "你需要根据知识点文本来设计多选题，以下是知识点文本：\n",
    "{text}\n",
    "\"\"\"\n",
    "# llm,_ = get_llm(\"glm\")\n",
    "llm=ChatOpenAI(openai_api_key=\"67f836edc96405d0c4eea5d8eeff70d0.pVev8zx1tG17ohTQ\",model_name=\"glm-4-airx\", temperature=0.7, base_url=\"https://open.bigmodel.cn/api/paas/v4/\")\n",
    "\n",
    "\n",
    "# llm = ChatOpenAI(openai_api_key=os.environ.get('DEEPSEEK_API_KEY'),\n",
    "#                  base_url=os.environ.get('DEEPSEEK_API_URL'),\n",
    "#                  model=\"deepseek-chat\",\n",
    "#                  top_p=0.7,\n",
    "#                  temperature=0.5)\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "\n",
    "    (\"system\", sys_prompt),\n",
    "\n",
    "])\n",
    "response_json=\"\"\"{\"1\": {\"question\": \"choice here\", \"C\": \"choice here\", \"D\": \"choice here\"}, \"correct\": \"correct answer\", \"explanation\": \"Detailed option explanations\"}, \"2\": {\"question\": \"multiple choice question\", \"options\": {\"A\": \"choice here\", \"B\": \"choice here\", \"C\": \"choice here\", \"D\": \"choice here\"}, \"correct\": \"correct answer\", \"explanation\": \"Detailed option explanations\"}, \"3\": {\"question\": \"multiple choice question\", \"options\": {\"A\": \"choice here\", \"B\": \"choice here\", \"C\": \"choice here\", \"D\": \"choice here\"}, \"correct\": \"correct answer\", \"explanation\": \"Detailed option explanations\"}}\"\"\"\n",
    "text=\"\"\"[Document(page_content='Entities:\\n- {\\'descriptionText\\': \\'图灵机是艾伦·图灵提出的一种抽象计算模型，它在可计算性问题以及人工智能发展史上具有非常重要的意义，并对计算机科学产生了深远Hebbian法则是一种关于神经网络学习的理论\\', \\'entityName\\': \\'HEBBIAN法则\\'}\\n- {\\'descriptionText\\': \\'图灵奖是计算机科学领域的国际最高奖项，Marvin Minsky于1969年获得此奖项\\', \\'enti\\'福岛邦彦提出了新知机模型\\', \\'entityName\\': \\'福岛邦彦\\'}\\n- {\\'descriptionText\\': \\'B型图灵机是一种可以基于Hebbian法则进行学习的机器\\', \\'entityName\\': \\'B型图灵机\\'}\\n- {\\'descri带卷积和子采样操作的多层神经网络由福岛邦彦提出的多层神经网络结构，采用无监督学习方式训练\\', \\'entityName\\': \\'新知机\\'}\\n- {\\'descriptionText\\': \\'赫布理论是Donald Hebb提出的关于神经: \\'Torch3是Lua语言的一个深度学习库，是PyTorch的前身\\', \\'entityName\\': \\'TORCH3\\'}\\n- {\\'descriptionText\\': \\'图灵测试是图灵提出的一个测试计算机能否展现出智能行为的准则\\', \\'entityN\\': \\'赫布型学习是基于赫布理论的学习方法\\', \\'entityName\\': \\'赫布型学习\\'}\\nReports:\\n- {\\'rank\\': 6.5, \\'weight\\': None, \\'summaryText\\': \"The community is centered around the concal Networks (ANN), which is a machine learning structure simulating the human brain\\'s neural network. Key entities include neurons, perceptrons, nodes, and various related concepts and individuals such as Donald Hebb and Rosenblatt. These entities are interconnected through relationships that define their roles and contributions to the field of artificial intelligence and machine learning.\"}\\n- {\\'rank\\': 6.5, \\'weight\\': None, \\'summaryText\\': \"The community is centered around the works of Donald Hebb, a renowned Canadian neuro-psychologist, and his contributions to the field of psychology, particularly his theories on learning and synaptic plasticity. The entities in this community are primarily theoretical concepts and professional entities directly linked to Hebb\\'s work and legacy.\"}\\n- {\\'rank\\': 6.5, \\'weight\\': None, \\'summaryText\\': \"The community is centered around the concept of Artificial Neural Networks (ANN), which is a machine learning structure simulating the human brain\\'s neural network. Key entities include neurons, perceptrons, nodes, and various related concepts and individuals such as Donald Hebb and Rosenblatt. These entities are interconnected through relationships that define their roles and contributions to the field of artificial intelligence and machine learning.\"}\\nChunks:\\n- {\\'chunkText\\': \\'函数），因此我们可以将人工神经网络看作一个可学习的函数，并将其应用到机器学习中．理论上，只要有足够的训练数据和神（Network Capacity），这与可以被储存在网络中的信息的复杂度以及数量相关．\\\\n1.5.3神经网络的发展历史神经网络的发展大致经过五个阶段．\\\\n第一阶段：模型提出第一阶段为1943 年～1969 年，是神和数学家Walter Pitts 最早提出了一种基于简单逻辑运算的人工神经网络，这种神经网络模型称为MP 模型，至此开启了人工神经网络研究的序幕．1948 年，Alan Turing 提出了一种“B 型图灵机”．\\\\n“B 型tts 的学生Marvin Minsky 建造了第一台神经网络机SNARC．\\\\nMarvin Minsky（1927～2016），人工智能领域最重要的领导者和创新者之一，麻省理工学院人工智能实验室的创始人之一．\\\\n因其在人工智能拟人类感知能力的神经网络模型，称为感知器（Percep-tron），并提出了一种接近于人类学习过程（迭代、试错）的学习算法．\\\\n在这一时期，神经网络以其独特的结构和处理信息的方法，在许多实际应用处于长年停滞及低潮状态．\\\\n1969 年，Marvin Minsky 出版《感知器》一书，指出了神经网络的两个关键缺陷：一是感知器无法处理“异或”回路问题；二是当时的计算机无法支持处理大https://nndl.githu的神经网络产生质疑，并导致神经网络的研究进入了十多年的“冰河期”．\\\\n但在这一时期，依然有不少学者提出了很多有用的模型或算法．1974 年，哈佛大学的Paul Werbos 发明反向传播算法（BackPropagNeocognitron）[Fukushima, 1980]．\\\\n新知机的提出是受到了动物初级视皮层简单细胞和复杂细胞的感受野的启发．\\\\n但新知机并没有采用反向传播算法，而是采用了无监督学习的方式来训练，因此也没有播算法重新�\\', \\'chunkId\\': \\'0a5689249dea5fa6e3eb9ba870a10ba4\\', \\'frequency\\': 5}\\n- {\\'chunkText\\': \\'科．\\\\n图1.1给出了人工智能发展史上的重要事件．\\\\n1940194519501955196019651970005McCulloch 和Pitts提出人工神经元网络图灵机达特茅斯会议Rosenblatt提出“感知器”推理期知识期学习期知识系统兴起专家系统兴起神经网络重新流行统计机器学习兴起（支持向量机等）深度学习的兴起然遥遥无期．\\\\nhttps://nndl.github.io/page_begin1.2机器学习2021 年5 月18 日61.1.2人工智能的流派目前我们对人类智能的机理依然知之甚少，还没有一个通用的理论来指导如何构建一个人工智能系统究人类智能的机理来构建一个仿生的模拟系统，而另外一些研究者则认为可以使用其他方法来实现人类的某种智能行为．\\\\n一个著名的例子是让机器具有飞行能力不需要模拟鸟的飞行方式，而是应该研究空气接主义和行为主义三种，其中行为主义（Actionism）主要从生物进化的角度考虑，主张从和外界环境的互动中获取智能．\\\\n（1）符号主义（Symbolism），又称逻辑主义、心理学派或计算机学派，是指通过作．\\\\n人类的认知过程可以看作符号操作过程．\\\\n在人工智能的推理期和知识期，符号主义的方法比较盛行，并取得了大量的成果．\\\\n（2）连接主义（Connectionism），又称仿生学派或生理学派，是认知经网络中的信息处理过程，而不是符号运算．\\\\n因此，连接主义模型的主要结构是由大量简单的信息处理单元组成的互联网络，具有非线性、分布式、并行化、局部性计算以及自适应性等特性．\\\\n符号主义主要模型神经网络就是一种连接主义模型．\\\\n随着深度学习的发展，越来越多的研究者开始关注如何融合符号主义和连接主义，建立一种高效并且具有可解释性的模型．\\\\n1.2机器学习机器学习（Machine LnkId\\': \\'8baca4b3f4003191a17a1f82b043fa52\\', \\'frequency\\': 2}\\n- {\\'chunkText\\': \\'学家Donald Hebb 在《行为的组织》（The Organization of Behavior）一书中提出突触可塑性的基本原理，D理学家，认知心理生理学的开创者．\\\\n“当神经元A 的一个轴突和神经元B 很近，足以对它产生影响，并且持续地、重复地参与了对神经元B 的兴奋，那么在这两个神经元或其中之一会发生某种生长过程或新或Hebb’s Rule）．\\\\n如果两个神经元总是相关联地受到刺激，它们之间的突触强度增加．\\\\n这样的学习方法被称为赫布型学习（Hebbian learning）．\\\\nHebb 认为人脑有两种记忆：长期记忆和短期记忆．固作用．\\\\n人脑中的海马区为大脑结构凝固作用的核心区域．\\\\n1.5.2人工神经网络人工神经网络是为模拟人脑神经网络而设计的一种计算模型，它从结构、实现机理和功能上模拟人脑神经网络．\\\\n人工神另一个节点的影响大小．\\\\n每个节点代表一种特定函数，来自其他节点的信息经过其相应的1 图片来源：https://commons.wikimedia.org/wiki/File:Neuron_Hand-tuned.svghttps://nndl.github.io/page_begin1.5神经网络2021 年5 月18 日14权重综合计算，输入到一个激活函数中并得到一个新的活性值（兴奋或抑制）．\\\\n从系统观点看，人工神经元网络是由大量神经元通过极其丰富和完善的连接而构成的自学习能力．\\\\n首个可学习的人工神经网络是赫布网络，采用一种基于赫布规则的无监督学习方法．\\\\n感知器是最早的具有机器学习思想的神经网络，但其学习方法无法扩展到多层的神经网络上．\\\\n感知器参习问题．\\\\n在本书中，人工神经网络主要是作为一种映射函数，即机器学习中的模型．\\\\n由于人工神经网络可以用作一个通用的函数逼近器（一个两层的神经网络可以逼近任意的函数），因此我们可以将人函数的能力\\', \\'chunkId\\': \\'84a8a6e9ba478ecb40b16e75fb368359\\', \\'frequency\\': 2}\\nRelationships:\\n- {\\'entityFrom\\': \\'图灵奖\\', \\'entityTo\\': \\'MARVIN MINSKY\\', \\'descriptionText\\vin Minsky因其在人工智能领域的贡献而获得图灵奖\\', \\'relation\\': \\'RELATED\\'}\\n- {\\'entityFrom\\': \\'赫布理论\\', \\'entityTo\\': \\'DONALD HEBB\\', \\'descriptionText\\': \\'Donald Hebb提出了ELATED\\'}\\n- {\\'entityFrom\\': \\'TORCH3\\', \\'entityTo\\': \\'PYTORCH\\', \\'descriptionText\\': \\'Torch3是PyTorch的前身，两者在技术继承上有关联\\', \\'relation\\': \\'RELATED\\'}\\n- {\\'entityFr \\'entityTo\\': \\'人工神经网络\\', \\'descriptionText\\': \\'赫布型学习是早期人工神经网络的一种学习方式赫布网络是首个可学习的人工神经网络，采用基于赫布规则的无监督学习方法\\', \\'relation\\'工智能\\', \\'descriptionText\\': \\'图灵机对人工智能的理论基础有重要贡献\\', \\'relation\\': \\'RELATED\\'}\\n- {\\'entityFrom\\': \\'福岛邦彦\\', \\'entityTo\\': \\'新知机\\', \\'descriptionText\\': \\网络的结构提供了新的视角\\', \\'relation\\': \\'RELATED\\'}\\n- {\\'entityFrom\\': \\'新知机\\', \\'entityTo\\': \\'福岛邦彦\\', \\'descriptionText\\': \\'福岛邦彦提出了新知机模型福岛邦彦提出新知机模TED\\'}\\n- {\\'entityFrom\\': \\'图灵机\\', \\'entityTo\\': \\'TURING TEST\\', \\'descriptionText\\': \\'图灵机模型和图灵测试都由图灵提出，对人工智能领域有深远影响\\', \\'relation\\': \\'RELATED\\'}\\T\\', \\'entityTo\\': \\'图灵机\\', \\'descriptionText\\': \\'图灵机模型和图灵测试都由图灵提出，对人工智能领域有深远影响\\', \\'relation\\': \\'RELATED\\'}\\n- {\\'entityFrom\\': \\'赫布理论\\', \\'entt\\': \\'赫布型学习是基于赫布理论的学习方法\\', \\'relation\\': \\'RELATED\\'}\\n- {\\'entityFrom\\'\"\"\"\n",
    "examples=\"\"\"{\n",
    "    \"1\": {\n",
    "        \"question\": \"关于强化学习和神经网络模型的结合使用，以下哪些描述是正确的？\",\n",
    "        \"options\": {\n",
    "            \"A\": \"强化学习可以看作是一种端到端的学习方法，其中每个内部组件直接从最终奖励中学习。\",\n",
    "            \"B\": \"在深度强化学习中，贡献度分配问题指的是如何合理地将整体奖励分配给各个决策步骤。\",\n",
    "            \"C\": \"误差反向传播算法主要用于监督学习，而不是强化学习。\",\n",
    "            \"D\": \"强化学习中的智能体通过与环境交互来优化策略，而不需要显式的训练数据集。\"\n",
    "        },\n",
    "        \"correct\": \"B, D\",\n",
    "        \"explanation\": \"B. 贡献度分配问题是深度强化学习中的一个关键问题，涉及如何将整体奖励分配给各个决策步骤。D. 强化学习的核心是通过与环境交互来学习最优策略，而不依赖于预先标记的数据集。A. 选项描述不准确，强化学习通常不是纯粹的端到端学习；C. 反向传播算法确实主要应用于监督学习，但在某些情况下也可用于强化学习中的策略梯度方法。\"\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"question\": \"下列关于神经元及其在人工神经网络中的模拟，哪几项是正确的？\",\n",
    "        \"options\": {\n",
    "            \"A\": \"神经元之间的连接强度（突触权重）在人工神经网络中是固定不变的。\",\n",
    "            \"B\": \"Hebbian理论认为，当两个神经元同时被激活时，它们之间的连接会变得更强。\",\n",
    "            \"C\": \"反向传播算法是由Paul Werbos提出的，它解决了多层神经网络中贡献度分配的问题。\",\n",
    "            \"D\": \"在生物神经元中，树突负责接收来自其他神经元的信息，轴突则负责传递信息至下一个神经元或效应器。\"\n",
    "        },\n",
    "        \"correct\": \"B, C, D\",\n",
    "        \"explanation\": \"B. Hebbian理论强调了神经元之间连接强度的可塑性，这是学习的基础。C. Paul Werbos确实在1974年提出了反向传播算法，该算法对于解决多层神经网络中的权重更新问题至关重要。D. 树突和轴突的功能正如所述。A. 神经网络中的突触权重是通过学习过程不断调整的，并非固定不变。\"\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"question\": \"关于特征表示方法以及其在机器学习中的应用，下列说法正确的是？\",\n",
    "        \"options\": {\n",
    "            \"A\": \"one-hot编码适合于表示连续变量。\",\n",
    "            \"B\": \"局部分表示如one-hot向量，通常用于表示离散特征，例如颜色。\",\n",
    "            \"C\": \"分布式表示相较于one-hot编码，能更好地捕捉特征间的相似性。\",\n",
    "            \"D\": \"嵌入（Embedding）技术仅适用于自然语言处理领域。\"\n",
    "        },\n",
    "        \"correct\": \"B, C\",\n",
    "        \"explanation\": \"B. one-hot向量常用来表示离散特征，比如不同的颜色。C. 分布式表示能够表达特征间的语义关系，这在one-hot编码中是无法实现的。A. one-hot编码不适合表示连续变量，因为它是为离散变量设计的。D. 嵌入技术不仅限于自然语言处理，也广泛应用于推荐系统等领域。\"\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "# Set up the language model and memory chain\n",
    "chain = prompt | llm\n",
    "user_input=\"请开始：\"\n",
    "result=chain.invoke({\"question\":user_input,\"examples\": examples,\"text\":text,\"response_json\":response_json})\n",
    "pprint(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8cb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb8f13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
