{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "quiz_str=\"\"\"{\n",
    "\"1\": {\n",
    "\"mcq\": \"在深度学习的发展历史中，哪一阶段被认为是神经网络发展的第一个高潮期？\",\n",
    "\"options\": {\n",
    "\"a\": \"第一阶段：模型提出\",\n",
    "\"b\": \"第二阶段：冰河期\",\n",
    "\"c\": \"第三阶段：反向传播算法引起的复兴\",\n",
    "\"d\": \"以上都不对\"\n",
    "},\n",
    "\"correct\": \"a\"\n",
    "},\n",
    "\"2\": {\n",
    "\"mcq\": \"哪一位科学家提出了Perceptron（感知器）的概念？\",\n",
    "\"options\": {\n",
    "\"a\": \"Warren McCulloch\",\n",
    "\"b\": \"Walter Pitts\",\n",
    "\"c\": \"Marvin Minsky\",\n",
    "\"d\": \"Alan Turing\"\n",
    "},\n",
    "\"correct\": \"c\"\n",
    "},\n",
    "\"3\": {\n",
    "\"mcq\": \"哪种方法被用于训练Neocognitron（新知机）？\",\n",
    "\"options\": {\n",
    "\"a\": \"监督学习\",\n",
    "\"b\": \"无监督学习\",\n",
    "\"c\": \"概率密度估计\",\n",
    "\"d\": \"自动微分\"\n",
    "},\n",
    "\"correct\": \"b\"\n",
    "}\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "quiz_dict=json.loads(quiz_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "165fd727ab1a0b77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T13:21:58.917240600Z",
     "start_time": "2024-10-18T13:21:11.853470200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='### 知识点主题：\\n本测验主要围绕“深度学习与神经网络模型”这一主题，涵盖图灵机、赫布理论及新知机等相关概念。这些知识点均属于计算机科学和人工智能领域的重要组成部分。\\n\\n### 关键知识点：\\n1. 图灵机的定义及其在计算领域的贡献\\n2. 赫布法则（Hebbian法则）与赫布型学习方法\\n3. 新知机模型由福岛邦彦提出\\n\\n---\\n\\n### 多选题设计：\\n\\n#### 题目 1:\\n以下关于图灵机的说法正确的是：\\n- A. 图灵机是艾伦·图灵提出的抽象计算模型。\\n- B. 图灵奖是计算机科学领域的国际最高奖项，Marvin Minsky于1969年获得此奖项。\\n- C. 赫布理论是Donald Hebb关于神经网络学习的理论。\\n- D. 图灵测试是由图灵提出的一个准则，用于测试机器是否展现出智能行为。\\n\\n**答案**: A, B, D\\n\\n**解释**: \\nA 正确。图灵机确实由艾伦·图灵提出，并且是一种抽象计算模型。\\nB 正确。虽然Marvin Minsky获得图灵奖与图灵机本身关系不大，但这一事实是正确的。\\nD 正确。图灵测试是图灵提出的用于判断机器智能的概念。\\n\\n#### 题目 2:\\n以下关于赫布法则及其相关理论的说法正确的是：\\n- A. 赫布理论由Donald Hebb提出，涉及到神经网络的学习机制。\\n- B. B型图灵机是一种可以基于Hebbian法则进行学习的机器。\\n- C. 福岛邦彦提出了新知机模型，这采用了无监督学习方式训练多层神经网络。\\n- D. 嵌入技术仅适用于自然语言处理领域。\\n\\n**答案**: A, C\\n\\n**解释**: \\nA 正确。赫布理论确实由Donald Hebb提出，并且涉及到了神经元之间连接强度的可塑性及学习机制。\\nB 错误。题目中没有提到B型图灵机与Hebbian法则之间的关系。\\nC 正确。福岛邦彦提出了新知机模型，该模型采用无监督学习方式训练多层神经网络结构。\\n\\n#### 题目 3:\\n关于新知机模型及其应用领域，下列说法正确的是：\\n- A. 新知机是一种基于Hebbian法则的机器。\\n- B. 福岛邦彦提出了新知机模型，并且该模型采用无监督学习方式训练多层神经网络结构。\\n- C. 嵌入技术仅适用于自然语言处理领域。\\n- D. 图灵测试由图灵提出，用于判断机器是否展现出智能行为。\\n\\n**答案**: B\\n\\n**解释**: \\nB 正确。新知机确实是由福岛邦彦提出的，并且该模型采用了无监督学习方式训练多层神经网络结构。\\nA 错误。题目中没有提到新知机是基于Hebbian法则的机器，只有B型图灵机提到了这一点。\\nC 错误。嵌入技术不仅仅适用于自然语言处理领域。\\nD 正确但不相关。图灵测试与本题核心“新知机模型”无关。\\n\\n以上题目设计旨在考察考生对于深度学习和神经网络模型中关键概念的理解。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 717, 'prompt_tokens': 1983, 'total_tokens': 2700, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'qwen2.5:32b', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-5c1a61fd-80bb-40fe-ab13-6cebe42d9c26-0', usage_metadata={'input_tokens': 1983, 'output_tokens': 717, 'total_tokens': 2700})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llm import get_llm\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "sys_prompt=template=\"\"\"\n",
    "# Role: 单项选择题的编写专家，多年执教经验的老师、命题人，懂得易错点和重点知识\n",
    "\n",
    "## Background: \n",
    "- 我希望能够根据一段知识点文本和要求生成一套高质量的单项选择题，能够通过试题反应出学生的知识掌握水平。\n",
    "\n",
    "## Attention:\n",
    "- 优秀的单项选择题是我们评估学生对知识掌握程度的重要工具。如果题目设计不当，无法准确反映学生的实际水平，可能会导致筛选出的学生并不真正掌握学科知识。因此，请务必高度重视题目设计的质量，确保能够筛选出对学科知识掌握牢固且正确的优秀学生。\n",
    "\n",
    "## Goals:\n",
    "- 题型要多样化、命题思路要严谨、涉及的知识点要全面的单项选择题，能够准确反馈出学生对知识的真实掌握程度。\n",
    "- 试题需要主题明确、知识点针对性强，错误选项需具有一定的干扰性，即看似合理但实则错误。正确答案决不允许胡编乱造。\n",
    "- 给定文本，你的任务是制作一个包含5道单项选择题的深度学习学科测验\n",
    "- 问题难度为：困难。\n",
    "\n",
    "## Workflows:\n",
    "1. 第一步：明确题目主题:\n",
    "2. 第二步：列出至少3个与主题紧密相关的关键知识点:\n",
    "3. 第三步：基于知识点文本，确保制作5道单项选择题，每道题须有4个选项，有且只有一个正确选项，，确保按照RESPONSE_JSON的格式组织你的回答，并将其作为指南。RESPONSE_JSON={response_json}\n",
    "\n",
    "## Rules:\n",
    "- 第三步必须是json格式(例如：```json内容..```)，确保按照RESPONSE_JSON的格式组织你的回答\n",
    "- 精心设计易错点，干扰选项需要有意义，使得干扰选项能够考验学生对知识点的掌握\n",
    "- 相关性——主题的具体性和复杂性 \n",
    "- 准确性——题干和正确答案必须有所依据 \n",
    "- 合理性——答案是一定存在的、高质量的、在上下文中有意义的\n",
    "- 清晰度——易于阅读；不混淆\n",
    "- 对于不精准或模棱两可的知识，请不要加入到试题中以免引起歧义。\n",
    "- 作为角色 <Role>, 严格遵守<Workflows>, 默认以中文语言完成要求。 \n",
    "\n",
    "## Examples:\n",
    "- {examples}\n",
    "\n",
    "\n",
    "## Text:\n",
    "你需要根据知识点文本来设计多选题，以下是知识点文本：\n",
    "{text}\n",
    "\"\"\"\n",
    "llm,_ = get_llm(\"Ollama\")\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",sys_prompt),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "response_json=\"\"\"{\"1\": {\"question\": \"choice here\", \"C\": \"choice here\", \"D\": \"choice here\"}, \"correct\": \"correct answer\", \"explanation\": \"Detailed option explanations\"}, \"2\": {\"question\": \"multiple choice question\", \"options\": {\"A\": \"choice here\", \"B\": \"choice here\", \"C\": \"choice here\", \"D\": \"choice here\"}, \"correct\": \"correct answer\", \"explanation\": \"Detailed option explanations\"}, \"3\": {\"question\": \"multiple choice question\", \"options\": {\"A\": \"choice here\", \"B\": \"choice here\", \"C\": \"choice here\", \"D\": \"choice here\"}, \"correct\": \"correct answer\", \"explanation\": \"Detailed option explanations\"}}\"\"\"\n",
    "text=\"\"\"[Document(page_content='Entities:\\n- {\\'descriptionText\\': \\'图灵机是艾伦·图灵提出的一种抽象计算模型，它在可计算性问题以及人工智能发展史上具有非常重要的意义，并对计算机科学产生了深远Hebbian法则是一种关于神经网络学习的理论\\', \\'entityName\\': \\'HEBBIAN法则\\'}\\n- {\\'descriptionText\\': \\'图灵奖是计算机科学领域的国际最高奖项，Marvin Minsky于1969年获得此奖项\\', \\'enti\\'福岛邦彦提出了新知机模型\\', \\'entityName\\': \\'福岛邦彦\\'}\\n- {\\'descriptionText\\': \\'B型图灵机是一种可以基于Hebbian法则进行学习的机器\\', \\'entityName\\': \\'B型图灵机\\'}\\n- {\\'descri带卷积和子采样操作的多层神经网络由福岛邦彦提出的多层神经网络结构，采用无监督学习方式训练\\', \\'entityName\\': \\'新知机\\'}\\n- {\\'descriptionText\\': \\'赫布理论是Donald Hebb提出的关于神经: \\'Torch3是Lua语言的一个深度学习库，是PyTorch的前身\\', \\'entityName\\': \\'TORCH3\\'}\\n- {\\'descriptionText\\': \\'图灵测试是图灵提出的一个测试计算机能否展现出智能行为的准则\\', \\'entityN\\': \\'赫布型学习是基于赫布理论的学习方法\\', \\'entityName\\': \\'赫布型学习\\'}\\nReports:\\n- {\\'rank\\': 6.5, \\'weight\\': None, \\'summaryText\\': \"The community is centered around the concal Networks (ANN), which is a machine learning structure simulating the human brain\\'s neural network. Key entities include neurons, perceptrons, nodes, and various related concepts and individuals such as Donald Hebb and Rosenblatt. These entities are interconnected through relationships that define their roles and contributions to the field of artificial intelligence and machine learning.\"}\\n- {\\'rank\\': 6.5, \\'weight\\': None, \\'summaryText\\': \"The community is centered around the works of Donald Hebb, a renowned Canadian neuro-psychologist, and his contributions to the field of psychology, particularly his theories on learning and synaptic plasticity. The entities in this community are primarily theoretical concepts and professional entities directly linked to Hebb\\'s work and legacy.\"}\\n- {\\'rank\\': 6.5, \\'weight\\': None, \\'summaryText\\': \"The community is centered around the concept of Artificial Neural Networks (ANN), which is a machine learning structure simulating the human brain\\'s neural network. Key entities include neurons, perceptrons, nodes, and various related concepts and individuals such as Donald Hebb and Rosenblatt. These entities are interconnected through relationships that define their roles and contributions to the field of artificial intelligence and machine learning.\"}\\nChunks:\\n- {\\'chunkText\\': \\'函数），因此我\"\"\"\n",
    "examples=\"\"\"{\n",
    "    \"1\": {\n",
    "        \"question\": \"关于强化学习和神经网络模型的结合使用，以下哪些描述是正确的？\",\n",
    "        \"options\": {\n",
    "            \"A\": \"强化学习可以看作是一种端到端的学习方法，其中每个内部组件直接从最终奖励中学习。\",\n",
    "            \"B\": \"在深度强化学习中，贡献度分配问题指的是如何合理地将整体奖励分配给各个决策步骤。\",\n",
    "            \"C\": \"误差反向传播算法主要用于监督学习，而不是强化学习。\",\n",
    "            \"D\": \"强化学习中的智能体通过与环境交互来优化策略，而不需要显式的训练数据集。\"\n",
    "        },\n",
    "        \"correct\": \"B, D\",\n",
    "        \"explanation\": \"B. 贡献度分配问题是深度强化学习中的一个关键问题，涉及如何将整体奖励分配给各个决策步骤。D. 强化学习的核心是通过与环境交互来学习最优策略，而不依赖于预先标记的数据集。A. 选项描述不准确，强化学习通常不是纯粹的端到端学习；C. 反向传播算法确实主要应用于监督学习，但在某些情况下也可用于强化学习中的策略梯度方法。\"\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"question\": \"下列关于神经元及其在人工神经网络中的模拟，哪几项是正确的？\",\n",
    "        \"options\": {\n",
    "            \"A\": \"神经元之间的连接强度（突触权重）在人工神经网络中是固定不变的。\",\n",
    "            \"B\": \"Hebbian理论认为，当两个神经元同时被激活时，它们之间的连接会变得更强。\",\n",
    "            \"C\": \"反向传播算法是由Paul Werbos提出的，它解决了多层神经网络中贡献度分配的问题。\",\n",
    "            \"D\": \"在生物神经元中，树突负责接收来自其他神经元的信息，轴突则负责传递信息至下一个神经元或效应器。\"\n",
    "        },\n",
    "        \"correct\": \"B, C, D\",\n",
    "        \"explanation\": \"B. Hebbian理论强调了神经元之间连接强度的可塑性，这是学习的基础。C. Paul Werbos确实在1974年提出了反向传播算法，该算法对于解决多层神经网络中的权重更新问题至关重要。D. 树突和轴突的功能正如所述。A. 神经网络中的突触权重是通过学习过程不断调整的，并非固定不变。\"\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"question\": \"关于特征表示方法以及其在机器学习中的应用，下列说法正确的是？\",\n",
    "        \"options\": {\n",
    "            \"A\": \"one-hot编码适合于表示连续变量。\",\n",
    "            \"B\": \"局部分表示如one-hot向量，通常用于表示离散特征，例如颜色。\",\n",
    "            \"C\": \"分布式表示相较于one-hot编码，能更好地捕捉特征间的相似性。\",\n",
    "            \"D\": \"嵌入（Embedding）技术仅适用于自然语言处理领域。\"\n",
    "        },\n",
    "        \"correct\": \"B, C\",\n",
    "        \"explanation\": \"B. one-hot向量常用来表示离散特征，比如不同的颜色。C. 分布式表示能够表达特征间的语义关系，这在one-hot编码中是无法实现的。A. one-hot编码不适合表示连续变量，因为它是为离散变量设计的。D. 嵌入技术不仅限于自然语言处理，也广泛应用于推荐系统等领域。\"\n",
    "    }\n",
    "}\"\"\"\n",
    "# Set up the language model and memory chain\n",
    "chain = prompt | llm\n",
    "user_input=\"请开始：\"\n",
    "chain.invoke({\"question\":user_input,\"examples\": examples,\"text\":text,\"response_json\":response_json})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d77610d8f41e618b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T02:54:17.962207Z",
     "start_time": "2024-10-19T02:53:19.230603900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain.docstore.document import Document\n",
    "from llm import get_llm\n",
    "\n",
    "relationship_properties = [\"comprehensiveDescriptionOfTheRelationship\"]\n",
    "node_properties = [\"comprehensiveDescriptionOfTheEntity\"]\n",
    "allowedRelationship = [\n",
    "    \"RELATED_TO\"\n",
    "]\n",
    "allowedNodes = [\n",
    "    \"Discipline\",\n",
    "    \"SubDiscipline\",\n",
    "    \"Concept\",\n",
    "    \"Theory\",\n",
    "    \"Method\",\n",
    "    \"Technology\",\n",
    "    \"Tool\",\n",
    "    \"Person\",\n",
    "    \"Event\",\n",
    "    \"Institution\",\n",
    "    \"Publication\",\n",
    "    \"Application\",\n",
    "    \"Experiment\",\n",
    "    \"KnowledgePoint\",\n",
    "]\n",
    "chunk_doc = Document(page_content=\"\"\"\n",
    "         \"31\": {\n",
    "            \"question\": \"下列哪个选项最准确地描述了前馈神经网络的特点？\",\n",
    "            \"options\": {\n",
    "                \"A\": \"从前隐藏层到输出层的路径中允许存在循环连接。\",\n",
    "                \"B\": \"通过时间递归处理序列数据，适合自然语言处理任务。\",\n",
    "                \"C\": \"信息仅从输入层单向传递至输出层，不包含任何反馈连接。\",\n",
    "                \"D\": \"主要用于图像识别任务，具备局部感受野和参数共享机制。\"\n",
    "            },\n",
    "            \"correct\": \"C\",\n",
    "            \"explanation\": \"前馈神经网络的信息只沿着一个方向从前隐藏层到输出层进行传递，没有反馈回路或循环结构。选项A描述了具有循环连接的神经网络（如RNN），B则是对循环神经网络特点的描述，而D则适用于卷积神经网络的特点。\"\n",
    "        },\n",
    "        \"32\": {\n",
    "            \"question\": \"关于反向传播算法在训练神经网络中的作用，以下哪个说法是正确的？\",\n",
    "            \"options\": {\n",
    "                \"A\": \"该算法通过随机选取权重来加速神经网络的学习过程。\",\n",
    "                \"B\": \"它负责优化模型的超参数，如学习率和批量大小。\",\n",
    "                \"C\": \"反向传播是一种用于更新神经网络中的权重的方法，以最小化损失函数。\",\n",
    "                \"D\": \"此方法主要用于数据预处理阶段，增强输入特征的质量。\"\n",
    "            },\n",
    "            \"correct\": \"C\",\n",
    "            \"explanation\": \"反向传播算法的核心作用是通过计算损失关于每个参数的梯度来更新神经网络的权重，目标是最小化预测输出与实际标签之间的差距（即损失函数）。选项A、B和D分别描述了不准确或无关的做法。\"\n",
    "        },\n",
    "        \"33\": {\n",
    "            \"question\": \"卷积神经网络广泛应用于图像识别任务的主要原因是什么？\",\n",
    "            \"options\": {\n",
    "                \"A\": \"因为它们能够捕捉到序列数据的时间依赖关系。\",\n",
    "                \"B\": \"可以实现局部感受野和参数共享，提高对平移不变性的处理能力。\",\n",
    "                \"C\": \"通过增加隐藏层的深度来降低模型复杂度并加速训练速度。\",\n",
    "                \"D\": \"卷积神经网络可以通过调整学习率自动适应不同的任务需求。\"\n",
    "            },\n",
    "            \"correct\": \"B\",\n",
    "            \"explanation\": \"卷积神经网络（CNN）特别适合图像识别，主要得益于其局部感受野和参数共享的特性，这有助于模型捕捉到输入信号中空间结构信息，并且保持对平移变换的不变性。选项A描述了RNN的特点；C、D则不准确地反映了训练或架构设计的原则。\"\n",
    "        },\n",
    "        \"34\": {\n",
    "            \"question\": \"注意力机制允许模型在处理序列数据时只关注输入中的关键部分。\",\n",
    "            \"options\": {\n",
    "                \"A\": \"True\",\n",
    "                \"B\": \"False\"\n",
    "            },\n",
    "            \"correct\": \"A\",\n",
    "            \"explanation\": \"注意力机制通过赋予不同位置不同的权重，使得模型能够更加聚焦于重要的信息。\"\n",
    "\n",
    "        \"\"\", metadata={})\n",
    "\n",
    "llm,_=get_llm(\"Ollama\")\n",
    "llm_transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=[\n",
    "    \"Discipline\",\"SubDiscipline\",\"Concept\",\"Theory\",\"Method\",\"Technology\",\"Tool\",\"Person\",\"Event\",\"Institution\",\"Publication\",\"Application\",\"Experiment\",\"KnowledgePoint\",],\n",
    "    node_properties=node_properties,\n",
    "    allowed_relationships=[\"APPLIED_IN\",\"CITED_BY\",\"HELD_AT\",\"INTRODUCES\",\"LAST_MESSAGE\",\"LIVES_IN\",\"PART_OF\",\"PROPOSED_BY\",\"PUBLISHED_IN\",\"RELATED_TO\",\"SIMILAR\",\"USED_IN\",\"WORKSFOR\"],\n",
    "    relationship_properties=relationship_properties,\n",
    ")\n",
    "result=llm_transformer.convert_to_graph_documents([chunk_doc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e91a9e6eee2dc552",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T02:51:27.497647900Z",
     "start_time": "2024-10-19T02:51:27.448247500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GraphDocument(nodes=[], relationships=[], source=Document(page_content='\\n         \"31\": {\\n            \"question\": \"下列哪个选项最准确地描述了前馈神经网络的特点？\",\\n            \"options\": {\\n                \"A\": \"从前隐藏层到输出层的路径中允许存在循环连接。\",\\n                \"B\": \"通过时间递归处理序列数据，适合自然语言处理任务。\",\\n                \"C\": \"信息仅从输入层单向传递至输出层，不包含任何反馈连接。\",\\n                \"D\": \"主要用于图像识别任务，具备局部感受野和参数共享机制。\"\\n            },\\n            \"correct\": \"C\",\\n            \"explanation\": \"前馈神经网络的信息只沿着一个方向从前隐藏层到输出层进行传递，没有反馈回路或循环结构。选项A描述了具有循环连接的神经网络（如RNN），B则是对循环神经网络特点的描述，而D则适用于卷积神经网络的特点。\"\\n        },\\n        \"32\": {\\n            \"question\": \"关于反向传播算法在训练神经网络中的作用，以下哪个说法是正确的？\",\\n            \"options\": {\\n                \"A\": \"该算法通过随机选取权重来加速神经网络的学习过程。\",\\n                \"B\": \"它负责优化模型的超参数，如学习率和批量大小。\",\\n                \"C\": \"反向传播是一种用于更新神经网络中的权重的方法，以最小化损失函数。\",\\n                \"D\": \"此方法主要用于数据预处理阶段，增强输入特征的质量。\"\\n            },\\n            \"correct\": \"C\",\\n            \"explanation\": \"反向传播算法的核心作用是通过计算损失关于每个参数的梯度来更新神经网络的权重，目标是最小化预测输出与实际标签之间的差距（即损失函数）。选项A、B和D分别描述了不准确或无关的做法。\"\\n        },\\n        \"33\": {\\n            \"question\": \"卷积神经网络广泛应用于图像识别任务的主要原因是什么？\",\\n            \"options\": {\\n                \"A\": \"因为它们能够捕捉到序列数据的时间依赖关系。\",\\n                \"B\": \"可以实现局部感受野和参数共享，提高对平移不变性的处理能力。\",\\n                \"C\": \"通过增加隐藏层的深度来降低模型复杂度并加速训练速度。\",\\n                \"D\": \"卷积神经网络可以通过调整学习率自动适应不同的任务需求。\"\\n            },\\n            \"correct\": \"B\",\\n            \"explanation\": \"卷积神经网络（CNN）特别适合图像识别，主要得益于其局部感受野和参数共享的特性，这有助于模型捕捉到输入信号中空间结构信息，并且保持对平移变换的不变性。选项A描述了RNN的特点；C、D则不准确地反映了训练或架构设计的原则。\"\\n        },\\n        \"34\": {\\n            \"question\": \"注意力机制允许模型在处理序列数据时只关注输入中的关键部分。\",\\n            \"options\": {\\n                \"A\": \"True\",\\n                \"B\": \"False\"\\n            },\\n            \"correct\": \"A\",\\n            \"explanation\": \"注意力机制通过赋予不同位置不同的权重，使得模型能够更加聚焦于重要的信息。\"\\n\\n        '))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ef83a8bc9296bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T11:14:44.415275400Z",
     "start_time": "2024-10-18T11:14:44.347284400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b97ba64809203024",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T03:03:48.471646800Z",
     "start_time": "2024-10-19T03:03:48.430524900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nodes': [{'id': '前馈神经网络', 'label': 'concept'},\n",
      "           {'id': '反向传播算法', 'label': 'concept'},\n",
      "           {'id': '卷积神经网络', 'label': 'concept'},\n",
      "           {'id': '注意力机制', 'label': 'concept'}],\n",
      " 'relationships': [{'end_node': '信息传递',\n",
      "                    'start_node': '前馈神经网络',\n",
      "                    'type': 'HAS_FEATURE'},\n",
      "                   {'end_node': '权重更新方法', 'start_node': '反向传播算法', 'type': 'IS'},\n",
      "                   {'end_node': '局部感受野',\n",
      "                    'start_node': '卷积神经网络',\n",
      "                    'type': 'HAS_FEATURE'},\n",
      "                   {'end_node': '参数共享',\n",
      "                    'start_node': '卷积神经网络',\n",
      "                    'type': 'HAS_FEATURE'},\n",
      "                   {'end_node': '关注关键部分',\n",
      "                    'start_node': '注意力机制',\n",
      "                    'type': 'HAS_FUNCTION'}]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint({\"nodes\":[{\"id\":\"前馈神经网络\",\"label\":\"concept\"},{\"id\":\"反向传播算法\",\"label\":\"concept\"},{\"id\":\"卷积神经网络\",\"label\":\"concept\"},{\"id\":\"注意力机制\",\"label\":\"concept\"}],\"relationships\":[{\"end_node\":\"信息传递\",\"start_node\":\"前馈神经网络\",\"type\":\"HAS_FEATURE\"},{\"end_node\":\"权重更新方法\",\"start_node\":\"反向传播算法\",\"type\":\"IS\"},{\"end_node\":\"局部感受野\",\"start_node\":\"卷积神经网络\",\"type\":\"HAS_FEATURE\"},{\"end_node\":\"参数共享\",\"start_node\":\"卷积神经网络\",\"type\":\"HAS_FEATURE\"},{\"end_node\":\"关注关键部分\",\"start_node\":\"注意力机制\",\"type\":\"HAS_FUNCTION\"}]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
